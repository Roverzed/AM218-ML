{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('anaconda3-2020.11': pyenv)",
   "metadata": {
    "interpreter": {
     "hash": "09b947ba581bcc337bc7c28ed026ab68f0805dc98e756a19c45c9bd5e23e2d3d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from sklearn.utils import shuffle as shuffle_ds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf(sigma=1):\n",
    "    #Guassian kernel function\n",
    "    def rbf_kernel(x1,x2,sigma):\n",
    "        X12norm = torch.sum(x1**2,1,keepdims=True)-2*x1@x2.T+torch.sum(x2**2,1,keepdims=True).T\n",
    "        return torch.exp(-X12norm/(2*sigma**2))\n",
    "    return lambda x1,x2: rbf_kernel(x1,x2,sigma)\n",
    "\n",
    "def poly(n=3):\n",
    "    #polynomial kernel function\n",
    "    return lambda x1,x2: (x1 @ x2.T)**n\n",
    "\n",
    "def grpf(sigma, d):\n",
    "    return lambda x1,x2: ((d + 2*rbf(sigma)(x1,x2))/(2 + d))**(d+1)\n",
    "def linf():\n",
    "    return lambda x1,x2: (x1@x2.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class svm_model_torch:\n",
    "    def __init__(self, m, n_class, device=\"cpu\"):\n",
    "        self.device = device\n",
    "        self.n_svm = n_class * (n_class - 1)//2\n",
    "        self.m = m # number of samples\n",
    "        self.n_class = n_class\n",
    "        self.blacklist = [set() for i in range(self.n_svm)]\n",
    "\n",
    "        # multiplier\n",
    "        self.a = torch.zeros((self.n_svm,self.m), device=self.device) # SMO works only when a is initialized to 0\n",
    "        # bias\n",
    "        self.b = torch.zeros((self.n_svm,1), device=self.device)\n",
    "\n",
    "        # kernel function  should input x [n,d] y [m,d] output [n,m]\n",
    "        # Example of poly kernel: lambda x,y:  torch.matmul(x,y.T)**2\n",
    "        self.kernel = lambda x,y:  torch.matmul(x,y.T)\n",
    "\n",
    "\n",
    "        # Binary setting for every SVM,\n",
    "        # Mij says the SVMj should give\n",
    "        # Mij label to sample with class i\n",
    "        self.lookup_matrix=torch.zeros((self.n_class, self.n_svm), device=self.device)\n",
    "\n",
    "        # The two classes SVMi concerns,\n",
    "        # lookup_class[i]=[pos, neg]\n",
    "        self.lookup_class=torch.zeros((self.n_svm, 2), device=self.device)\n",
    "\n",
    "        k=0\n",
    "        for i in range(n_class-1):\n",
    "            for j in range(i+1,n_class):\n",
    "                self.lookup_class[k, 0]=i\n",
    "                self.lookup_class[k, 1]=j\n",
    "                k += 1\n",
    "\n",
    "        for i in range(n_class):\n",
    "            for j in range(self.n_svm):\n",
    "                if i == self.lookup_class[j,0] or i == self.lookup_class[j,1]:\n",
    "                    if self.lookup_class[j, 0]==i:\n",
    "                        self.lookup_matrix[i,j]=1.0\n",
    "                    else:\n",
    "                        self.lookup_matrix[i,j]=-1.0\n",
    "\n",
    "    def fit(self, x_np, y_multiclass_np, C, iterations=1, kernel=rbf(1)):\n",
    "        x_np, y_multiclass_np = shuffle_ds(x_np,y_multiclass_np)\n",
    "        self.C = C # box constraint\n",
    "        # use SMO algorithm to fit\n",
    "        x = torch.from_numpy(x_np).float() if not torch.is_tensor(x_np) else x_np\n",
    "        x = x.to(self.device)\n",
    "        self.x = x.to(self.device)\n",
    "\n",
    "        y_multiclass = torch.from_numpy(y_multiclass_np).view(-1,1) if not torch.is_tensor(y_multiclass_np) else y_multiclass_np\n",
    "        y_multiclass = y_multiclass.view(-1)\n",
    "        self.y_matrix = torch.stack([self.cast(y_multiclass, k) for k in range(self.n_svm)],0).to(self.device)\n",
    "        self.kernel = kernel\n",
    "        a = self.a\n",
    "        b = self.b\n",
    "        for iteration in range(iterations):\n",
    "            print(\"Iteration: \",iteration)\n",
    "            for k in range(self.n_svm):\n",
    "                y = self.y_matrix[k, :].view(-1).tolist()\n",
    "                index = [i for i in range(len(y)) if y[i]!=0]\n",
    "                shuffle(index)\n",
    "                traverse = []\n",
    "                if index is not None:\n",
    "                    traverse = [i for i in range(0, len(index)-1, 2)]\n",
    "                    if len(index)>2:\n",
    "                         traverse += [len(index)-2]\n",
    "                for i in traverse:\n",
    "                    if str(index[i])+str(index[i+1]) not in self.blacklist[k]:\n",
    "                        y1 = y[index[i]]\n",
    "                        y2 = y[index[i+1]]\n",
    "                        x1 = x[index[i],:].view(1,-1)\n",
    "                        x2 = x[index[i+1],:].view(1,-1)\n",
    "                        a1_old = a[k,index[i]].clone()\n",
    "                        a2_old = a[k,index[i+1]].clone()\n",
    "\n",
    "                        if y1 != y2:\n",
    "                            H = max(min(self.C, (self.C + a2_old-a1_old).item()),0)\n",
    "                            L = min(max(0, (a2_old-a1_old).item()),self.C)\n",
    "                        else:\n",
    "                            H = max(min(self.C, (a2_old + a1_old).item()),0)\n",
    "                            L = min(max(0, (a2_old + a1_old - self.C).item()),self.C)\n",
    "                        E1 =  self.g_k(k, x1) - y1\n",
    "                        E2 =  self.g_k(k, x2) - y2\n",
    "                        a2_new = torch.clamp(a2_old + y2 * (E1-E2)/self.kernel(x1 - x2,x1 - x2), min=L, max=H)\n",
    "                        a[k,index[i+1]] = a2_new\n",
    "\n",
    "                        a1_new = a1_old - y1 * y2 * (a2_new - a2_old)\n",
    "                        a[k, index[i]] = a1_new\n",
    "\n",
    "                        b_old = b[k,0]\n",
    "                        K11 = self.kernel(x1,x1)\n",
    "                        K12 = self.kernel(x1,x2)\n",
    "                        K22 = self.kernel(x2,x2)\n",
    "                        b1_new = b_old - E1 + (a1_old-a1_new)*y1*K11+(a2_old-a2_new)*y2*K12\n",
    "                        b2_new = b_old - E2 + (a1_old-a1_new)*y1*K12+(a2_old-a2_new)*y2*K22\n",
    "                        if (0<a1_new) and (a1_new<self.C):\n",
    "                            b[k,0] = b1_new\n",
    "                        if (0<a2_new) and (a2_new<self.C):\n",
    "                            b[k,0] = b2_new\n",
    "                        if ((a1_new == 0) or (a1_new ==self.C)) and ((a2_new == 0) or (a2_new==self.C)) and (L!=H):\n",
    "                            b[k,0] = (b1_new + b2_new)/2\n",
    "                        if b_old == b[k,0] and a[k,index[i]] == a1_old and a[k,index[i+1]] == a2_old:\n",
    "                            self.blacklist[k].add(str(index[i]) + str(index[i+1]))\n",
    "\n",
    "    def predict(self,x_np):\n",
    "        xp = torch.from_numpy(x_np) if not torch.is_tensor(x_np) else x_np\n",
    "        xp = xp.float().to(self.device)\n",
    "        k_predicts = (self.y_matrix.to(self.device) * self.a) @ self.kernel(xp,self.x).T  + self.b\n",
    "        result = torch.argmax(self.lookup_matrix @ k_predicts,axis=0)\n",
    "        return result.to(\"cpu\").numpy()\n",
    "\n",
    "    def cast(self, y, k):\n",
    "        # cast the multiclass label of dataset to\n",
    "        # the pos/neg (with 0) where pos/neg are what SVMk concerns\n",
    "        return (y==self.lookup_class[k, 0]).float() - (y==self.lookup_class[k, 1]).float()\n",
    "\n",
    "\n",
    "    def wTx(self,k,xi):\n",
    "        # The prediction of SVMk without bias, w^T @ xi\n",
    "        y = self.y_matrix[k, :].reshape((-1,1))\n",
    "        a = self.a[k,:].view(-1,1)\n",
    "        wTx0 =  self.kernel(xi, self.x) @ (y * a)\n",
    "        return wTx0\n",
    "\n",
    "\n",
    "    def g_k(self,k,xi):\n",
    "        # The prediction of SVMk, xi[1,d]\n",
    "        return self.wTx(k,xi) + self.b[k,0].view(1,1)\n",
    "\n",
    "\n",
    "    def get_w(self, k):\n",
    "        y = self.cast(self.y_multiclass_np, k)\n",
    "        a = self.a[k,:].view(-1,1)\n",
    "        return torch.sum(a*y*self.x,0).view(-1,1)\n",
    "\n",
    "    def get_svms(self):\n",
    "        for k in range(self.n_svm):\n",
    "            sk = 'g' + str(self.lookup_class[k, 0].item()) + str(self.lookup_class[k, 1].item()) + '(x)='\n",
    "            w = self.get_w(k)\n",
    "            for i in range(w.shape[0]):\n",
    "                sk += \"{:.3f}\".format(w[i,0].item()) + ' x' + \"{:d}\".format(i) +' + '\n",
    "            sk += \"{:.3f}\".format(self.b[k,0].item())\n",
    "            print(sk)\n",
    "\n",
    "    def get_avg_pct_spt_vec(self):\n",
    "        # the average percentage of support vectors,\n",
    "        # test error shouldn't be greater than it if traing converge\n",
    "        return torch.sum((0.0<self.a) & (self.a<self.C)).float().item()/(self.n_svm*self.m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "data = pd.read_csv(path+\"/spambase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set(data,i):\n",
    "    N,L = data.shape\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    x_train = data.iloc[:int(N*i),:-1].values.reshape(-1,L-1)\n",
    "    y_train = data.iloc[:int(N*i),-1].values.reshape(-1,1)\n",
    "    x_test = data.iloc[int(N*i):,:-1].values.reshape(-1,L-1)\n",
    "    y_test = data.iloc[int(N*i):,-1].values.reshape(-1,1)\n",
    "    return torch.from_numpy(x_train).float(),torch.from_numpy(x_test).float(),torch.from_numpy(y_train).float(),torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = get_set(data,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration:  0\n",
      "Iteration:  1\n",
      "Iteration:  2\n",
      "Iteration:  3\n",
      "Iteration:  4\n",
      "Iteration:  5\n",
      "Iteration:  6\n",
      "Iteration:  7\n",
      "Iteration:  8\n",
      "Iteration:  9\n",
      "[0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = len(train_x)\n",
    "c = len(np.unique(train_y))\n",
    "svm = svm_model_torch(m,c)\n",
    "svm.fit(train_x,train_y,1,10)\n",
    "\n",
    "print(svm.predict(train_x)) # 预测结果\n",
    "# svm.get_svms() # Cn2 个SVM分类界面的表达式\n",
    "# print(svm.a)  # 拉格朗日乘子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3220, 57])"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "train_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5474798"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "(svm.predict(train_x) == np.array(train_y)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}