{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =    0 loss = 2.6644e-01\n",
      "step =  100 loss = 2.5338e-01\n",
      "step =  200 loss = 2.5284e-01\n",
      "step =  300 loss = 2.5004e-01\n",
      "step =  400 loss = 2.5242e-01\n",
      "step =  500 loss = 2.5332e-01\n",
      "step =  600 loss = 2.5238e-01\n",
      "step =  700 loss = 2.5238e-01\n",
      "step =  800 loss = 2.5256e-01\n",
      "step =  900 loss = 2.5036e-01\n",
      "step = 1000 loss = 2.5245e-01\n",
      "step = 1100 loss = 2.5185e-01\n",
      "step = 1200 loss = 2.5520e-01\n",
      "step = 1300 loss = 2.6737e-01\n",
      "step = 1400 loss = 2.6596e-01\n",
      "step = 1500 loss = 2.7246e-01\n",
      "step = 1600 loss = 2.6005e-01\n",
      "step = 1700 loss = 2.6196e-01\n",
      "step = 1800 loss = 2.5313e-01\n",
      "step = 1900 loss = 2.6177e-01\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6cb4531e77a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "n = 500\n",
    "x = torch.rand(n, 2)\n",
    "y = torch.Tensor([[1] if (k[0]+k[1]<1 or k[1]-k[0]<0)  else [0] for k in x])\n",
    "\n",
    "class mm_cls(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mm_cls, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(2, 5)\n",
    "        self.l2 = lambda x: x**2\n",
    "        self.l3 = torch.nn.Linear(5, 2)\n",
    "        self.l4 = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.l1(x)\n",
    "        x2 = self.l2(x1)\n",
    "        x3 = self.l3(x2)\n",
    "        x4 = self.l4(x3)\n",
    "        return x4\n",
    "    \n",
    "mm = mm_cls()\n",
    "\n",
    "loss_fun = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mm.parameters(),lr=0.001)\n",
    "\n",
    "epochs = 2000\n",
    "for i in range(epochs):\n",
    "    y_hat = mm.forward(x)\n",
    "\n",
    "    loss = loss_fun(y_hat, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print('step = %4d'%i, 'loss = %.4e'%loss.item())\n",
    "\n",
    "    optimizer.zero_grad\n",
    "\n",
    "y_hat = y_hat[:,0] < y_hat[:,1]\n",
    "y = y[:,0] < y[:,1]\n",
    "\n",
    "acc = accuracy_score(y_hat, y)\n",
    "print('acc = %f' % acc)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(x[y==1, 0], x[y==1, 1], 'om')\n",
    "plt.plot(x[y==0, 0], x[y==0, 1], 'ob')\n",
    "plt.title('original')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(x[y_hat==1, 0], x[y_hat==1, 1], 'om')\n",
    "plt.plot(x[y_hat==0, 0], x[y_hat==0, 1], 'ob')\n",
    "plt.title('predicted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21.7160, grad_fn=<MseLossBackward>)\n",
      "tensor(19.6735, grad_fn=<MseLossBackward>)\n",
      "tensor(19.0796, grad_fn=<MseLossBackward>)\n",
      "tensor(18.5621, grad_fn=<MseLossBackward>)\n",
      "tensor(18.0905, grad_fn=<MseLossBackward>)\n",
      "tensor(17.6884, grad_fn=<MseLossBackward>)\n",
      "/Users/zed/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# 一定要继承 nn.Module\n",
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.twolayernet = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.twolayernet(x)\n",
    "        return y_pred\n",
    "\n",
    "# M是样本数量，input_size是输入层大小， hidden_size是隐含层大小，output_size是输出层大小\n",
    "M, input_size, hidden_size, output_size = 64, 2, 2, 1\n",
    "n = 100\n",
    "# 生成随机数当作样本\n",
    "x = torch.rand(n, 2)\n",
    "y = torch.Tensor([[1] if (k[0]+k[1]<1 or k[1]-k[0]<0)  else [0] for k in x])\n",
    "\n",
    "model = TwoLayerNet(input_size, hidden_size, output_size)\n",
    "\n",
    "# 定义损失函数\n",
    "loss_fn = nn.MSELoss(size_average=False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "EPOCH = 300\n",
    "\n",
    "# 使用optim包来定义优化算法\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(EPOCH):    \n",
    "    y_pred= model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if (t+1) % 50 == 0:\n",
    "        print(loss)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a5e74a9fd06d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acc = %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_pred, y)\n",
    "print('acc = %f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zed/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 利用Pytorch解决XOR问题\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "n = 500\n",
    "x = torch.rand(n, 2)\n",
    "y = torch.Tensor([ 1 if (k[0]+k[1]<1 or k[1]-k[0]<0)  else 0 for k in x])\n",
    "\n",
    "\n",
    "\n",
    "# 初始化权重变量\n",
    "def weight_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 1.)\n",
    "        m.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "class XOR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XOR, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 2)   # 一个隐藏层 2个神经元\n",
    "        self.fc2 = nn.Linear(2,2)   # 输出层 1个神经元\n",
    "        self.fc3 = nn.Linear(2,1)\n",
    "    def forward(self, x):\n",
    "        h1 = F.sigmoid(self.fc1(x))  # 之前也尝试过用ReLU作为激活函数, 太容易死亡ReLU了.\n",
    "        h2 = F.sigmoid(self.fc2(h1))\n",
    "        h3 = torch.sign(self.fc3(h2))\n",
    "        return h3\n",
    "\n",
    "\n",
    "net = XOR()\n",
    "net.apply(weight_init_normal)\n",
    "x = torch.Tensor(x.reshape(-1, 2))\n",
    "y = torch.Tensor(y.reshape(-1, 1))\n",
    "\n",
    "# 定义loss function\n",
    "criterion = nn.BCELoss()  # MSE\n",
    "# 定义优化器\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)  # SGD\n",
    "# 训练\n",
    "for epoch in range(100000):\n",
    "    optimizer.zero_grad()   # 清零梯度缓存区\n",
    "    out = net(x)\n",
    "    loss = criterion(out, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()  # 更新\n",
    "\n",
    "# 测试\n",
    "test = net(x)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7700])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(out.detach() == y.detach())/y.detach().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('anaconda3-2020.11': pyenv)",
   "name": "python385jvsc74a57bd009b947ba581bcc337bc7c28ed026ab68f0805dc98e756a19c45c9bd5e23e2d3d"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}