{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python370jvsc74a57bd022cbdd8659c8ce3000871c3febea23388912970a6baae5fd58def00b2403d874",
   "display_name": "Python 3.7.0 64-bit ('anaconda3-5.3.1': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(28, 28, 1) 10\n",
      "Epoch 1/10\n",
      "1875/1875 - 2s - loss: 1.4624 - accuracy: 0.6985 - val_loss: 0.8867 - val_accuracy: 0.8266\n",
      "Epoch 2/10\n",
      "1875/1875 - 1s - loss: 0.7198 - accuracy: 0.8438 - val_loss: 0.5785 - val_accuracy: 0.8680\n",
      "Epoch 3/10\n",
      "1875/1875 - 1s - loss: 0.5352 - accuracy: 0.8706 - val_loss: 0.4681 - val_accuracy: 0.8856\n",
      "Epoch 4/10\n",
      "1875/1875 - 1s - loss: 0.4560 - accuracy: 0.8833 - val_loss: 0.4129 - val_accuracy: 0.8929\n",
      "Epoch 5/10\n",
      "1875/1875 - 1s - loss: 0.4117 - accuracy: 0.8905 - val_loss: 0.3792 - val_accuracy: 0.8989\n",
      "Epoch 6/10\n",
      "1875/1875 - 1s - loss: 0.3830 - accuracy: 0.8960 - val_loss: 0.3564 - val_accuracy: 0.9026\n",
      "Epoch 7/10\n",
      "1875/1875 - 1s - loss: 0.3626 - accuracy: 0.8999 - val_loss: 0.3402 - val_accuracy: 0.9054\n",
      "Epoch 8/10\n",
      "1875/1875 - 1s - loss: 0.3471 - accuracy: 0.9031 - val_loss: 0.3267 - val_accuracy: 0.9086\n",
      "Epoch 9/10\n",
      "1875/1875 - 1s - loss: 0.3346 - accuracy: 0.9061 - val_loss: 0.3174 - val_accuracy: 0.9120\n",
      "Epoch 10/10\n",
      "1875/1875 - 1s - loss: 0.3244 - accuracy: 0.9087 - val_loss: 0.3080 - val_accuracy: 0.9134\n",
      "Test Accuracy on the test set: 0.913\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import asarray\n",
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import random\n",
    "\n",
    "# load dataset\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "# # Explore the dataset\n",
    "# # summarize loaded dataset\n",
    "# print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "# print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
    "# # plot first few images\n",
    "# for i in range(25):\n",
    "#     plt.subplot(5, 5, i+1)\n",
    "#     plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
    "# plt.show()\n",
    "\n",
    "# fix the random seed\n",
    "random.seed(1)\n",
    "\n",
    "# reshape data to have a single channel\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
    "\n",
    "# determine the shape of the input images\n",
    "in_shape = x_train.shape[1:]\n",
    "\n",
    "# determine the number of classes\n",
    "n_classes = len(unique(y_train))\n",
    "print(in_shape, n_classes)\n",
    "\n",
    "# normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "\n",
    "# # Convolution layer with 32 3 by 3 filters, the activation is relu\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # Max pooling layer with 2 by 2 pooling window.\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# # First hidden layer with 100 hidden nodes\n",
    "model.add(Dense(units=100, activation='sigmoid'))\n",
    "\n",
    "# # The output layer with 10 classes output.\n",
    "# # Use the softmax activation function for classification\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# define loss function and optimizer\n",
    "# set the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use cross entropy as the loss for multi-class classification\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc)\n",
    "\n",
    "\n",
    "# make a prediction\n",
    "# image = x_train[0]\n",
    "# yhat = model.predict(asarray([image]))\n",
    "# print('Predicted: class=%d' % argmax(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 1s - loss: 0.6651 - accuracy: 0.8310 - val_loss: 0.3636 - val_accuracy: 0.9002\n",
      "Epoch 2/10\n",
      "1875/1875 - 1s - loss: 0.3456 - accuracy: 0.9035 - val_loss: 0.3014 - val_accuracy: 0.9139\n",
      "Epoch 3/10\n",
      "1875/1875 - 1s - loss: 0.2978 - accuracy: 0.9165 - val_loss: 0.2711 - val_accuracy: 0.9222\n",
      "Epoch 4/10\n",
      "1875/1875 - 1s - loss: 0.2681 - accuracy: 0.9252 - val_loss: 0.2481 - val_accuracy: 0.9279\n",
      "Epoch 5/10\n",
      "1875/1875 - 1s - loss: 0.2452 - accuracy: 0.9309 - val_loss: 0.2273 - val_accuracy: 0.9362\n",
      "Epoch 6/10\n",
      "1875/1875 - 1s - loss: 0.2265 - accuracy: 0.9365 - val_loss: 0.2120 - val_accuracy: 0.9406\n",
      "Epoch 7/10\n",
      "1875/1875 - 1s - loss: 0.2106 - accuracy: 0.9410 - val_loss: 0.1993 - val_accuracy: 0.9448\n",
      "Epoch 8/10\n",
      "1875/1875 - 1s - loss: 0.1973 - accuracy: 0.9450 - val_loss: 0.1890 - val_accuracy: 0.9466\n",
      "Epoch 9/10\n",
      "1875/1875 - 1s - loss: 0.1854 - accuracy: 0.9487 - val_loss: 0.1788 - val_accuracy: 0.9495\n",
      "Epoch 10/10\n",
      "1875/1875 - 1s - loss: 0.1746 - accuracy: 0.9510 - val_loss: 0.1696 - val_accuracy: 0.9512\n",
      "Test Accuracy on the test set: 0.951\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model2 = Sequential()\n",
    "\n",
    "# # Convolution layer with 32 3 by 3 filters, the activation is relu\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # Max pooling layer with 2 by 2 pooling window.\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Flatten layer\n",
    "model2.add(Flatten())\n",
    "\n",
    "# # First hidden layer with 100 hidden nodes\n",
    "model2.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "# # The output layer with 10 classes output.\n",
    "# # Use the softmax activation function for classification\n",
    "model2.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# define loss function and optimizer\n",
    "# set the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use cross entropy as the loss for multi-class classification\n",
    "model2.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss2, acc2 = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 1s - loss: 0.2746 - accuracy: 0.9217 - val_loss: 0.1439 - val_accuracy: 0.9571\n",
      "Epoch 2/10\n",
      "1875/1875 - 1s - loss: 0.1259 - accuracy: 0.9636 - val_loss: 0.1101 - val_accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "1875/1875 - 1s - loss: 0.0892 - accuracy: 0.9733 - val_loss: 0.0928 - val_accuracy: 0.9719\n",
      "Epoch 4/10\n",
      "1875/1875 - 1s - loss: 0.0679 - accuracy: 0.9793 - val_loss: 0.0920 - val_accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "1875/1875 - 1s - loss: 0.0535 - accuracy: 0.9840 - val_loss: 0.0773 - val_accuracy: 0.9756\n",
      "Epoch 6/10\n",
      "1875/1875 - 1s - loss: 0.0432 - accuracy: 0.9869 - val_loss: 0.0834 - val_accuracy: 0.9749\n",
      "Epoch 7/10\n",
      "1875/1875 - 1s - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.0786 - val_accuracy: 0.9777\n",
      "Epoch 8/10\n",
      "1875/1875 - 1s - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.0774 - val_accuracy: 0.9780\n",
      "Epoch 9/10\n",
      "1875/1875 - 1s - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.0948 - val_accuracy: 0.9730\n",
      "Epoch 10/10\n",
      "1875/1875 - 1s - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.0781 - val_accuracy: 0.9789\n",
      "Test Accuracy on the test set: 0.979\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model3 = Sequential()\n",
    "\n",
    "# # Convolution layer with 32 3 by 3 filters, the activation is relu\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # Max pooling layer with 2 by 2 pooling window.\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Flatten layer\n",
    "model3.add(Flatten())\n",
    "\n",
    "# # First hidden layer with 100 hidden nodes\n",
    "model3.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "# # The output layer with 10 classes output.\n",
    "# # Use the softmax activation function for classification\n",
    "model3.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# define loss function and optimizer\n",
    "# set the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use cross entropy as the loss for multi-class classification\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model3.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss3, acc3 = model3.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 2s - loss: 0.2643 - accuracy: 0.9245 - val_loss: 0.1510 - val_accuracy: 0.9555\n",
      "Epoch 2/10\n",
      "1875/1875 - 1s - loss: 0.1179 - accuracy: 0.9647 - val_loss: 0.1037 - val_accuracy: 0.9684\n",
      "Epoch 3/10\n",
      "1875/1875 - 1s - loss: 0.0817 - accuracy: 0.9752 - val_loss: 0.0986 - val_accuracy: 0.9703\n",
      "Epoch 4/10\n",
      "1875/1875 - 1s - loss: 0.0616 - accuracy: 0.9810 - val_loss: 0.0793 - val_accuracy: 0.9742\n",
      "Epoch 5/10\n",
      "1875/1875 - 1s - loss: 0.0477 - accuracy: 0.9852 - val_loss: 0.0825 - val_accuracy: 0.9756\n",
      "Epoch 6/10\n",
      "1875/1875 - 1s - loss: 0.0393 - accuracy: 0.9876 - val_loss: 0.0682 - val_accuracy: 0.9804\n",
      "Epoch 7/10\n",
      "1875/1875 - 1s - loss: 0.0302 - accuracy: 0.9909 - val_loss: 0.0775 - val_accuracy: 0.9781\n",
      "Epoch 8/10\n",
      "1875/1875 - 1s - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.0787 - val_accuracy: 0.9774\n",
      "Epoch 9/10\n",
      "1875/1875 - 1s - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0789 - val_accuracy: 0.9786\n",
      "Epoch 10/10\n",
      "1875/1875 - 1s - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.0895 - val_accuracy: 0.9778\n",
      "Test Accuracy on the test set: 0.978\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model3 = Sequential()\n",
    "\n",
    "# # Convolution layer with 32 3 by 3 filters, the activation is relu\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # Max pooling layer with 2 by 2 pooling window.\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Flatten layer\n",
    "model3.add(Flatten())\n",
    "\n",
    "# # First hidden layer with 100 hidden nodes\n",
    "model3.add(Dense(units=125, activation='relu'))\n",
    "\n",
    "# # The output layer with 10 classes output.\n",
    "# # Use the softmax activation function for classification\n",
    "model3.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# define loss function and optimizer\n",
    "# set the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use cross entropy as the loss for multi-class classification\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model3.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss3, acc3 = model3.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 2s - loss: 0.2444 - accuracy: 0.9291 - val_loss: 0.1168 - val_accuracy: 0.9621\n",
      "Epoch 2/10\n",
      "1875/1875 - 1s - loss: 0.1018 - accuracy: 0.9698 - val_loss: 0.0899 - val_accuracy: 0.9729\n",
      "Epoch 3/10\n",
      "1875/1875 - 1s - loss: 0.0728 - accuracy: 0.9771 - val_loss: 0.0807 - val_accuracy: 0.9743\n",
      "Epoch 4/10\n",
      "1875/1875 - 1s - loss: 0.0561 - accuracy: 0.9829 - val_loss: 0.0842 - val_accuracy: 0.9736\n",
      "Epoch 5/10\n",
      "1875/1875 - 1s - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.0755 - val_accuracy: 0.9770\n",
      "Epoch 6/10\n",
      "1875/1875 - 1s - loss: 0.0363 - accuracy: 0.9883 - val_loss: 0.0847 - val_accuracy: 0.9756\n",
      "Epoch 7/10\n",
      "1875/1875 - 1s - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.0856 - val_accuracy: 0.9773\n",
      "Epoch 8/10\n",
      "1875/1875 - 1s - loss: 0.0251 - accuracy: 0.9914 - val_loss: 0.0875 - val_accuracy: 0.9782\n",
      "Epoch 9/10\n",
      "1875/1875 - 1s - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0960 - val_accuracy: 0.9741\n",
      "Epoch 10/10\n",
      "1875/1875 - 1s - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.1029 - val_accuracy: 0.9752\n",
      "Test Accuracy on the test set: 0.975\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model4 = Sequential()\n",
    "\n",
    "# # Convolution layer with 32 3 by 3 filters, the activation is relu\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # Max pooling layer with 2 by 2 pooling window.\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Flatten layer\n",
    "model4.add(Flatten())\n",
    "\n",
    "# # First hidden layer with 100 hidden nodes\n",
    "model4.add(Dense(units=100, activation='relu'))\n",
    "model4.add(Dense(units=100,activation=\"relu\"))\n",
    "# # The output layer with 10 classes output.\n",
    "# # Use the softmax activation function for classification\n",
    "model4.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# define loss function and optimizer\n",
    "# set the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use cross entropy as the loss for multi-class classification\n",
    "model4.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model4.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss4, acc4 = model4.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 15s - loss: 0.1654 - accuracy: 0.9503 - val_loss: 0.0695 - val_accuracy: 0.9759\n",
      "Epoch 2/10\n",
      "1875/1875 - 14s - loss: 0.0580 - accuracy: 0.9821 - val_loss: 0.0563 - val_accuracy: 0.9814\n",
      "Epoch 3/10\n",
      "1875/1875 - 15s - loss: 0.0367 - accuracy: 0.9888 - val_loss: 0.0415 - val_accuracy: 0.9855\n",
      "Epoch 4/10\n",
      "1875/1875 - 15s - loss: 0.0254 - accuracy: 0.9921 - val_loss: 0.0459 - val_accuracy: 0.9854\n",
      "Epoch 5/10\n",
      "1875/1875 - 16s - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.0477 - val_accuracy: 0.9850\n",
      "Epoch 6/10\n",
      "1875/1875 - 25s - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0636 - val_accuracy: 0.9825\n",
      "Epoch 7/10\n",
      "1875/1875 - 44s - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.0492 - val_accuracy: 0.9878\n",
      "Epoch 8/10\n",
      "1875/1875 - 25s - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0531 - val_accuracy: 0.9866\n",
      "Epoch 9/10\n",
      "1875/1875 - 24s - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.0500 - val_accuracy: 0.9868\n",
      "Epoch 10/10\n",
      "1875/1875 - 19s - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0560 - val_accuracy: 0.9859\n",
      "Test Accuracy on the test set: 0.986\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model5 = Sequential()\n",
    "\n",
    "# # Convolution layer with 32 3 by 3 filters, the activation is relu\n",
    "model5.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # Max pooling layer with 2 by 2 pooling window.\n",
    "model5.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Flatten layer\n",
    "model5.add(Flatten())\n",
    "\n",
    "# # First hidden layer with 100 hidden nodes\n",
    "model5.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "# # The output layer with 10 classes output.\n",
    "# # Use the softmax activation function for classification\n",
    "model5.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# define loss function and optimizer\n",
    "# set the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use cross entropy as the loss for multi-class classification\n",
    "model5.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model5.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss5, acc5 = model5.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}