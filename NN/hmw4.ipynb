{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1) 10\n",
      "Epoch 1/10\n",
      "1875/1875 - 2s - loss: 1.4761 - accuracy: 0.6963 - val_loss: 0.9011 - val_accuracy: 0.8332\n",
      "Epoch 2/10\n",
      "1875/1875 - 1s - loss: 0.7294 - accuracy: 0.8422 - val_loss: 0.5843 - val_accuracy: 0.8687\n",
      "Epoch 3/10\n",
      "1875/1875 - 1s - loss: 0.5405 - accuracy: 0.8691 - val_loss: 0.4723 - val_accuracy: 0.8831\n",
      "Epoch 4/10\n",
      "1875/1875 - 1s - loss: 0.4597 - accuracy: 0.8818 - val_loss: 0.4145 - val_accuracy: 0.8919\n",
      "Epoch 5/10\n",
      "1875/1875 - 1s - loss: 0.4146 - accuracy: 0.8902 - val_loss: 0.3804 - val_accuracy: 0.8998\n",
      "Epoch 6/10\n",
      "1875/1875 - 1s - loss: 0.3855 - accuracy: 0.8949 - val_loss: 0.3572 - val_accuracy: 0.9022\n",
      "Epoch 7/10\n",
      "1875/1875 - 1s - loss: 0.3647 - accuracy: 0.8993 - val_loss: 0.3411 - val_accuracy: 0.9064\n",
      "Epoch 8/10\n",
      "1875/1875 - 1s - loss: 0.3489 - accuracy: 0.9019 - val_loss: 0.3278 - val_accuracy: 0.9085\n",
      "Epoch 9/10\n",
      "1875/1875 - 1s - loss: 0.3366 - accuracy: 0.9048 - val_loss: 0.3172 - val_accuracy: 0.9117\n",
      "Epoch 10/10\n",
      "1875/1875 - 1s - loss: 0.3263 - accuracy: 0.9075 - val_loss: 0.3085 - val_accuracy: 0.9131\n",
      "Test Accuracy on the test set: 0.913\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import asarray\n",
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import random\n",
    "\n",
    "# load dataset\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "# # Explore the dataset\n",
    "# # summarize loaded dataset\n",
    "# print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "# print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
    "# # plot first few images\n",
    "# for i in range(25):\n",
    "#     plt.subplot(5, 5, i+1)\n",
    "#     plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
    "# plt.show()\n",
    "\n",
    "# fix the random seed\n",
    "random.seed(1)\n",
    "\n",
    "# reshape data to have a single channel\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
    "\n",
    "# determine the shape of the input images\n",
    "in_shape = x_train.shape[1:]\n",
    "\n",
    "# determine the number of classes\n",
    "n_classes = len(unique(y_train))\n",
    "print(in_shape, n_classes)\n",
    "\n",
    "# normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# define model\n",
    "model1 = Sequential()\n",
    "\n",
    "# # Convolution layer with 32 3 by 3 filters, the activation is relu\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # Max pooling layer with 2 by 2 pooling window.\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Flatten layer\n",
    "model1.add(Flatten())\n",
    "\n",
    "# # First hidden layer with 100 hidden nodes\n",
    "model1.add(Dense(units=100, activation='sigmoid'))\n",
    "\n",
    "# # The output layer with 10 classes output.\n",
    "# # Use the softmax activation function for classification\n",
    "model1.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# define loss function and optimizer\n",
    "# set the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use cross entropy as the loss for multi-class classification\n",
    "model1.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model1.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss, acc = model1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc)\n",
    "\n",
    "\n",
    "# make a prediction\n",
    "# image = x_train[0]\n",
    "# yhat = model.predict(asarray([image]))\n",
    "# print('Predicted: class=%d' % argmax(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 1s - loss: 0.6409 - accuracy: 0.8364 - val_loss: 0.3564 - val_accuracy: 0.9061\n",
      "Epoch 2/10\n",
      "1875/1875 - 1s - loss: 0.3414 - accuracy: 0.9043 - val_loss: 0.2950 - val_accuracy: 0.9177\n",
      "Epoch 3/10\n",
      "1875/1875 - 1s - loss: 0.2957 - accuracy: 0.9171 - val_loss: 0.2646 - val_accuracy: 0.9247\n",
      "Epoch 4/10\n",
      "1875/1875 - 1s - loss: 0.2671 - accuracy: 0.9247 - val_loss: 0.2443 - val_accuracy: 0.9316\n",
      "Epoch 5/10\n",
      "1875/1875 - 1s - loss: 0.2454 - accuracy: 0.9311 - val_loss: 0.2281 - val_accuracy: 0.9336\n",
      "Epoch 6/10\n",
      "1875/1875 - 1s - loss: 0.2275 - accuracy: 0.9360 - val_loss: 0.2118 - val_accuracy: 0.9395\n",
      "Epoch 7/10\n",
      "1875/1875 - 1s - loss: 0.2124 - accuracy: 0.9409 - val_loss: 0.1983 - val_accuracy: 0.9419\n",
      "Epoch 8/10\n",
      "1875/1875 - 1s - loss: 0.1985 - accuracy: 0.9448 - val_loss: 0.1891 - val_accuracy: 0.9461\n",
      "Epoch 9/10\n",
      "1875/1875 - 1s - loss: 0.1865 - accuracy: 0.9481 - val_loss: 0.1773 - val_accuracy: 0.9497\n",
      "Epoch 10/10\n",
      "1875/1875 - 1s - loss: 0.1759 - accuracy: 0.9510 - val_loss: 0.1679 - val_accuracy: 0.9527\n",
      "Test Accuracy on the test set: 0.953\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model2 = Sequential()\n",
    "\n",
    "# # Convolution layer with 32 3 by 3 filters, the activation is relu\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # Max pooling layer with 2 by 2 pooling window.\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Flatten layer\n",
    "model2.add(Flatten())\n",
    "\n",
    "# # First hidden layer with 100 hidden nodes\n",
    "model2.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "# # The output layer with 10 classes output.\n",
    "# # Use the softmax activation function for classification\n",
    "model2.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# define loss function and optimizer\n",
    "# set the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use cross entropy as the loss for multi-class classification\n",
    "model2.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss2, acc2 = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 2s - loss: 0.2744 - accuracy: 0.9214 - val_loss: 0.1361 - val_accuracy: 0.9608\n",
      "Epoch 2/10\n",
      "1875/1875 - 1s - loss: 0.1213 - accuracy: 0.9633 - val_loss: 0.1007 - val_accuracy: 0.9694\n",
      "Epoch 3/10\n",
      "1875/1875 - 1s - loss: 0.0847 - accuracy: 0.9750 - val_loss: 0.0893 - val_accuracy: 0.9735\n",
      "Epoch 4/10\n",
      "1875/1875 - 1s - loss: 0.0646 - accuracy: 0.9807 - val_loss: 0.0799 - val_accuracy: 0.9740\n",
      "Epoch 5/10\n",
      "1875/1875 - 1s - loss: 0.0512 - accuracy: 0.9844 - val_loss: 0.0773 - val_accuracy: 0.9753\n",
      "Epoch 6/10\n",
      "1875/1875 - 1s - loss: 0.0418 - accuracy: 0.9873 - val_loss: 0.0837 - val_accuracy: 0.9735\n",
      "Epoch 7/10\n",
      "1875/1875 - 1s - loss: 0.0338 - accuracy: 0.9893 - val_loss: 0.0772 - val_accuracy: 0.9770\n",
      "Epoch 8/10\n",
      "1875/1875 - 1s - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.0794 - val_accuracy: 0.9761\n",
      "Epoch 9/10\n",
      "1875/1875 - 1s - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.0748 - val_accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "1875/1875 - 1s - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0812 - val_accuracy: 0.9766\n",
      "Test Accuracy on the test set: 0.977\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model3 = Sequential()\n",
    "\n",
    "# # Convolution layer with 32 3 by 3 filters, the activation is relu\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # Max pooling layer with 2 by 2 pooling window.\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Flatten layer\n",
    "model3.add(Flatten())\n",
    "\n",
    "# # First hidden layer with 100 hidden nodes\n",
    "model3.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "# # The output layer with 10 classes output.\n",
    "# # Use the softmax activation function for classification\n",
    "model3.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# define loss function and optimizer\n",
    "# set the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use cross entropy as the loss for multi-class classification\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model3.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss3, acc3 = model3.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 2s - loss: 0.2620 - accuracy: 0.9251 - val_loss: 0.1484 - val_accuracy: 0.9569\n",
      "Epoch 2/10\n",
      "1875/1875 - 1s - loss: 0.1147 - accuracy: 0.9658 - val_loss: 0.1050 - val_accuracy: 0.9692\n",
      "Epoch 3/10\n",
      "1875/1875 - 1s - loss: 0.0780 - accuracy: 0.9771 - val_loss: 0.0795 - val_accuracy: 0.9763\n",
      "Epoch 4/10\n",
      "1875/1875 - 1s - loss: 0.0577 - accuracy: 0.9824 - val_loss: 0.0776 - val_accuracy: 0.9773\n",
      "Epoch 5/10\n",
      "1875/1875 - 2s - loss: 0.0456 - accuracy: 0.9861 - val_loss: 0.0785 - val_accuracy: 0.9749\n",
      "Epoch 6/10\n",
      "1875/1875 - 2s - loss: 0.0353 - accuracy: 0.9892 - val_loss: 0.0775 - val_accuracy: 0.9779\n",
      "Epoch 7/10\n",
      "1875/1875 - 1s - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.0719 - val_accuracy: 0.9787\n",
      "Epoch 8/10\n",
      "1875/1875 - 2s - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.0796 - val_accuracy: 0.9774\n",
      "Epoch 9/10\n",
      "1875/1875 - 1s - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0722 - val_accuracy: 0.9784\n",
      "Epoch 10/10\n",
      "1875/1875 - 1s - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0842 - val_accuracy: 0.9761\n",
      "Test Accuracy on the test set: 0.976\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model4 = Sequential()\n",
    "\n",
    "# # Convolution layer with 32 3 by 3 filters, the activation is relu\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # Max pooling layer with 2 by 2 pooling window.\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Flatten layer\n",
    "model4.add(Flatten())\n",
    "\n",
    "# # First hidden layer with 100 hidden nodes\n",
    "model4.add(Dense(units=125, activation='relu'))\n",
    "\n",
    "# # The output layer with 10 classes output.\n",
    "# # Use the softmax activation function for classification\n",
    "model4.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# define loss function and optimizer\n",
    "# set the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use cross entropy as the loss for multi-class classification\n",
    "model4.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model4.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss4, acc4 = model4.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 2s - loss: 0.2452 - accuracy: 0.9285 - val_loss: 0.1216 - val_accuracy: 0.9623\n",
      "Epoch 2/10\n",
      "1875/1875 - 1s - loss: 0.1025 - accuracy: 0.9689 - val_loss: 0.0973 - val_accuracy: 0.9694\n",
      "Epoch 3/10\n",
      "1875/1875 - 2s - loss: 0.0724 - accuracy: 0.9771 - val_loss: 0.0793 - val_accuracy: 0.9755\n",
      "Epoch 4/10\n",
      "1875/1875 - 1s - loss: 0.0549 - accuracy: 0.9827 - val_loss: 0.0780 - val_accuracy: 0.9764\n",
      "Epoch 5/10\n",
      "1875/1875 - 1s - loss: 0.0436 - accuracy: 0.9856 - val_loss: 0.0725 - val_accuracy: 0.9777\n",
      "Epoch 6/10\n",
      "1875/1875 - 1s - loss: 0.0364 - accuracy: 0.9879 - val_loss: 0.0866 - val_accuracy: 0.9758\n",
      "Epoch 7/10\n",
      "1875/1875 - 1s - loss: 0.0302 - accuracy: 0.9901 - val_loss: 0.0869 - val_accuracy: 0.9759\n",
      "Epoch 8/10\n",
      "1875/1875 - 1s - loss: 0.0260 - accuracy: 0.9912 - val_loss: 0.0825 - val_accuracy: 0.9795\n",
      "Epoch 9/10\n",
      "1875/1875 - 1s - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.0946 - val_accuracy: 0.9758\n",
      "Epoch 10/10\n",
      "1875/1875 - 1s - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.0938 - val_accuracy: 0.9764\n",
      "Test Accuracy on the test set: 0.976\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model5 = Sequential()\n",
    "\n",
    "# # C5nvolution layer with 32 3 by 3 filters, the activation is relu\n",
    "# mod5l.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # M5x pooling layer with 2 by 2 pooling window.\n",
    "# mod5l.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# # F5atten layer\n",
    "model5.add(Flatten())\n",
    "\n",
    "# # F5rst hidden layer with 100 hidden nodes\n",
    "model5.add(Dense(units=100, activation='relu'))\n",
    "model5.add(Dense(units=100,activation=\"relu\"))\n",
    "# # T5e output layer with 10 classes output.\n",
    "# # U5e the softmax activation function for classification\n",
    "model5.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# def5ne loss function and optimizer\n",
    "# set5the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use5cross entropy as the loss for multi-class classification\n",
    "model5.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model5.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# eva5uate the model\n",
    "loss5 ,acc5 = model5.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 15s - loss: 0.1686 - accuracy: 0.9492 - val_loss: 0.0688 - val_accuracy: 0.9745\n",
      "Epoch 2/10\n",
      "1875/1875 - 14s - loss: 0.0576 - accuracy: 0.9824 - val_loss: 0.0472 - val_accuracy: 0.9846\n",
      "Epoch 3/10\n",
      "1875/1875 - 13s - loss: 0.0369 - accuracy: 0.9883 - val_loss: 0.0449 - val_accuracy: 0.9852\n",
      "Epoch 4/10\n",
      "1875/1875 - 15s - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.0577 - val_accuracy: 0.9829\n",
      "Epoch 5/10\n",
      "1875/1875 - 14s - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.0440 - val_accuracy: 0.9860\n",
      "Epoch 6/10\n",
      "1875/1875 - 14s - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0491 - val_accuracy: 0.9866\n",
      "Epoch 7/10\n",
      "1875/1875 - 15s - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.0485 - val_accuracy: 0.9855\n",
      "Epoch 8/10\n",
      "1875/1875 - 14s - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0608 - val_accuracy: 0.9846\n",
      "Epoch 9/10\n",
      "1875/1875 - 14s - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0618 - val_accuracy: 0.9852\n",
      "Epoch 10/10\n",
      "1875/1875 - 14s - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0612 - val_accuracy: 0.9876\n",
      "Test Accuracy on the test set: 0.988\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model6 = Sequential()\n",
    "\n",
    "# # C6nvolution layer with 32 3 by 3 filters, the activation is relu\n",
    "model6.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # M6x pooling layer with 2 by 2 pooling window.\n",
    "model6.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# # F6atten layer\n",
    "model6.add(Flatten())\n",
    "\n",
    "# # F6rst hidden layer with 100 hidden nodes\n",
    "model6.add(Dense(units=100, activation='relu'))\n",
    "model6.add(Dense(units=100,activation=\"relu\"))\n",
    "# # T6e output layer with 10 classes output.\n",
    "# # U6e the softmax activation function for classification\n",
    "model6.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# def6ne loss function and optimizer\n",
    "# set6the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use6cross entropy as the loss for multi-class classification\n",
    "model6.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model6.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss6, acc6 = model6.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 - 81s - loss: 0.1304 - accuracy: 0.9596 - val_loss: 0.0644 - val_accuracy: 0.9799\n",
      "Epoch 2/20\n",
      "1875/1875 - 77s - loss: 0.0411 - accuracy: 0.9876 - val_loss: 0.0707 - val_accuracy: 0.9799\n",
      "Epoch 3/20\n",
      "1875/1875 - 76s - loss: 0.0229 - accuracy: 0.9925 - val_loss: 0.0683 - val_accuracy: 0.9838\n",
      "Epoch 4/20\n",
      "1875/1875 - 77s - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.0885 - val_accuracy: 0.9815\n",
      "Epoch 5/20\n",
      "1875/1875 - 76s - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0795 - val_accuracy: 0.9811\n",
      "Epoch 6/20\n",
      "1875/1875 - 75s - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0890 - val_accuracy: 0.9818\n",
      "Epoch 7/20\n",
      "1875/1875 - 76s - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0891 - val_accuracy: 0.9829\n",
      "Epoch 8/20\n",
      "1875/1875 - 75s - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.1085 - val_accuracy: 0.9797\n",
      "Epoch 9/20\n",
      "1875/1875 - 473s - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0905 - val_accuracy: 0.9869\n",
      "Epoch 10/20\n",
      "1875/1875 - 2770s - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1097 - val_accuracy: 0.9822\n",
      "Epoch 11/20\n",
      "1875/1875 - 84s - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0967 - val_accuracy: 0.9857\n",
      "Epoch 12/20\n",
      "1875/1875 - 78s - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1446 - val_accuracy: 0.9804\n",
      "Epoch 13/20\n",
      "1875/1875 - 78s - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0857 - val_accuracy: 0.9851\n",
      "Epoch 14/20\n",
      "1875/1875 - 77s - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0981 - val_accuracy: 0.9848\n",
      "Epoch 15/20\n",
      "1875/1875 - 77s - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1143 - val_accuracy: 0.9846\n",
      "Epoch 16/20\n",
      "1875/1875 - 470s - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1219 - val_accuracy: 0.9848\n",
      "Epoch 17/20\n",
      "1875/1875 - 77s - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.1313 - val_accuracy: 0.9863\n",
      "Epoch 18/20\n",
      "1875/1875 - 77s - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.1402 - val_accuracy: 0.9835\n",
      "Epoch 19/20\n",
      "1875/1875 - 77s - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1509 - val_accuracy: 0.9838\n",
      "Epoch 20/20\n",
      "1875/1875 - 77s - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.1273 - val_accuracy: 0.9851\n",
      "Test Accuracy on the test set: 0.985\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model7 = Sequential()\n",
    "\n",
    "# # C7nvolution layer with 32 3 by 3 filters, the activation is relu\n",
    "model7.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "\n",
    "# # M7x pooling layer with 2 by 2 pooling window.\n",
    "model7.add(MaxPool2D(pool_size=(1, 1)))\n",
    "\n",
    "# # F7atten layer\n",
    "model7.add(Flatten())\n",
    "\n",
    "# # F7rst hidden layer with 100 hidden nodes\n",
    "model7.add(Dense(units=300, activation='relu'))\n",
    "model7.add(Dense(units=300,activation=\"relu\"))\n",
    "# # T7e output layer with 10 classes output.\n",
    "# # U7e the softmax activation function for classification\n",
    "model7.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# def7ne loss function and optimizer\n",
    "# set7the optimizer to 'sgd', then you may switch to 'adam'.\n",
    "# use7cross entropy as the loss for multi-class classification\n",
    "model7.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model7.fit(x_train, y_train, epochs=20, batch_size=32, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss7, acc7 = model7.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Accuracy on the test set: %.3f' % acc7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('base': conda)",
   "language": "python",
   "name": "python370jvsc74a57bd022cbdd8659c8ce3000871c3febea23388912970a6baae5fd58def00b2403d874"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}